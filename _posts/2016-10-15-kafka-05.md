---
layout: post
title: kafka 5
categories: [kafka]
keywords: kafka
---

**0.9.0**

### FAQ

如何回溯过去?


### Controllers

how it works

### Broker HA 机制

![](/images/posts/kafka/broker_ha.png)

从图中我们可以看出HA的缓存分为生产缓存事件池和拉取缓存事件池两块结构相同的缓存区，分别缓存生产和拉取请求

2个缓存事件池的作用:

1. 生产缓存事件池：当生产者设置了等待从partition的同步选项(requiredAcks为-1)时才会启动生产缓存。
   因为每一批生产的消息，需要等待所有的处于同步状态的从partition（in-sync）同步成功，在所有follow partition上报自
   己的水位线追上leader partition之前，生产请求会一直保留在生产缓存中，等待直到超时。
2. 拉取缓存事件池：拉取请求为什么也需要缓存？因为kafka在消费消息时有一个默认选项，一次拉取最低消费1条消息。
   那么，如果消费者拉取的时候没有任何新消息生产，则拉取请求会保留到拉取缓存中，等待直到超时。这一定程度上避免了
   反复拉取一批空消息占用带宽资源的问题，不过也把Kafka的ha缓存架构的复杂度提升了一个等级。

```scala
ReplicaManager:

val delayedProducePurgatory = new DelayedOperationPurgatory[DelayedProduce](
    purgatoryName = "Produce", config.brokerId, config.producerPurgatoryPurgeIntervalRequests)
val delayedFetchPurgatory = new DelayedOperationPurgatory[DelayedFetch](
    purgatoryName = "Fetch", config.brokerId, config.fetchPurgatoryPurgeIntervalRequests)
```

更新时间, 正如上面所说的, 当消息到来后才会触发缓冲事件池的活动

```scala
if (leaderHWIncremented)
    tryCompleteDelayedRequests()

private def tryCompleteDelayedRequests() {
    // key 就是一个 topic 和 partition
    val requestKey = new TopicPartitionOperationKey(this.topic, this.partitionId)
    replicaManager.tryCompleteDelayedFetch(requestKey)
    replicaManager.tryCompleteDelayedProduce(requestKey)
}
```

Replica 读取 leader 更新 HW 后怎么通知 replicaManager?

注意, 这里的 tryComplete 并不会阻塞线程

回头看看 Fetch 的流程

```scala
KafkaApis:
def handleFetchRequest(request: RequestChannel.Request) {
    replicaManager.fetchMessages()

// Fetch messages from the leader replica, and wait until enough data can be fetched and return;
// the callback function will be triggered either when timeout or required fetch info is satisfied

def fetchMessages(timeout: Long,
                    replicaId: Int,
                    fetchMinBytes: Int,
                    fetchInfo: immutable.Map[TopicAndPartition, PartitionFetchInfo],
                    responseCallback: Map[TopicAndPartition, FetchResponsePartitionData] => Unit) {
    val logReadResults = readFromLocalLog(fetchOnlyFromLeader, fetchOnlyCommitted, fetchInfo)

```


**DelayedOperation**

```scala
DelayedOperation
    DelayedFetch
    DelayedProduce
```

## 几个小问题 @todo 源码

### Partition Recovery 机制

每个Partition会在磁盘记录一个RecoveryPoint, 记录已经flush到磁盘的最大offset。
当broker fail 重启时,会进行loadLogs。 首先会读取该 Partition 的 RecoveryPoint,
找到包含RecoveryPoint的segment及以后的segment, 这些segment就是可能没有完全flush到磁盘segments
然后调用segment的recover,重新读取各个segment的msg,并重建索引

[好像和我理解的不同, 我理解的是 logsegments 只会恢复数据, 读数据应该还是去 Leader 中获取把]

partition 在文件系统中的存储
```
ls data/kafka/kafka_data

__consumer_offsets-0                    iacallhome-0                            test2-2
__consumer_offsets-1                    icam_kafka_raw-1                        test2-3
__consumer_offsets-10

cd test2-2

00000000001050803083.index  00000000001072557976.index  00000000001093802376.index
00000000001050803083.log    00000000001072557976.log    00000000001093802376.log
```

这里面的每个 log 对应的都是一个 logsegments

Log 启动与加载

```scala
// log 自带 recoveryPoint
class Log(val dir: File,
          @volatile var config: LogConfig,
          @volatile var recoveryPoint: Long = 0L,
          scheduler: Scheduler,
          time: Time = SystemTime) extends Logging with KafkaMetricsGroup {
// how log created when broker start up?

private def loadSegments() {
    // 第一遍 pass 删除非法文件, 对于 swap 文件特殊处理
    // 第二遍 pass 加载 segments
    } else if(filename.endsWith(LogFileSuffix)) {
        val start = filename.substring(0, filename.length - LogFileSuffix.length).toLong
        val indexFile = Log.indexFilename(dir, start)
        val segment = new LogSegment(dir = dir, startOffset = start, fileAlreadyExists = true)
        segments.put(start, segment)            

    // recover 处于 swap 状态的 log
    for (swapFile <- swapFiles) {
        val swapSegment = new LogSegment(new FileMessageSet(file = swapFile),
        swapSegment.recover(config.maxMessageSize)
```

文件也并没有加载到内存, 只是在内存中维护了一个这个东西, 表示文件存在而已

```scala
// 一个 Message 的格式
* A message. The format of an N byte message is the following:
 *
 * 1. 4 byte CRC32 of the message
 * 2. 1 byte "magic" identifier to allow format changes, value is 0 currently
 * 3. 1 byte "attributes" identifier to allow annotations on the message independent of the version (e.g. compression enabled, type of codec used)
 * 4. 4 byte key length, containing length K
 * 5. K byte key
 * 6. 4 byte payload length, containing length V
 * 7. V byte payload
 *
 * Default constructor wraps an existing ByteBuffer with the Message object with no change to the contents.


logSegment.recover: crc 校验

def recover(maxMessageSize: Int): Int = {
    val iter = log.iterator(maxMessageSize)
    while(iter.hasNext) {
        entry.message.ensureValid() // 如果不正常就报错, 确认方式是 checksum == computeChecksum, crc 循环冗余校验
        if(validBytes - lastIndexEntry > indexIntervalBytes) // 此 Message 大于一个 indexInterval, index 添加一项纪录
            index.append(startOffset, validBytes)
            lastIndexEntry = validBytes
        validBytes += MessageSet.entrySize(entry.message)
```

![](/images/posts/kafka/kafka_message_format.png)

左边的是 index, 右边的是 log, log 是由 message 组成的

此外, 每个 Log (一个 Partition) 由很多 logsegment 组成

当 Partition 启动的时候, 会 recoveryPointCheckPoints


**优点**

1. 以segment为单位管理Partition数据,方便数据生命周期的管理,删除过期数据简单
2. 在程序崩溃重启时,加快recovery速度,只需恢复未完全flush到磁盘的segment
3. 通过index中offset与物理偏移映射,用二分查找能快速定位msg,并且通过分多个Segment,每个index文件很小,查找速度更快。

数据结构

```scala
Parititon: Data structure that represents a topic partition. The leader maintains the AR, ISR, CUR, RAR
本身不含数据, 持有 ReplicaManager 引用, 保存 Partition 状态
    ReplicaManager: 持有 logManager 引用, 纪录HW, 可以 appendMessage, 代表一个 broker, 可以作为 leader
        LogManager: 纪录 data dir 下的所有文件, 纪录 Partition -> Log 的对应关系, 可以增删查改 Log
            Log: 和文件打交道了

```

LogManager 负责 recovery

```scala
LogManager.startup
def startup() {
      scheduler.schedule("kafka-recovery-point-checkpoint",
                         checkpointRecoveryPointOffsets,
                         delay = InitialTaskDelayMs,
                         period = flushCheckpointMs,
                         TimeUnit.MILLISECONDS)    
  def checkpointRecoveryPointOffsets()
    this.logDirs.foreach(checkpointLogsInDir)

  private def checkpointLogsInDir(dir: File): Unit =
    val recoveryPoints = this.logsByDir.get(dir.toString)
    if (recoveryPoints.isDefined) {
      this.recoveryPointCheckpoints(dir).write(recoveryPoints.get.mapValues(_.recoveryPoint))
```

recoveryPointCheckPoints 从每个 Topic 的 Log 中记录当前的 recoverPoint, 表示已经写入 disk 中的数据,

这本是 Log 的数据, 但是 LogManager 本身也管着


### Partition Replica同步机制

1. Partition的多个replica中一个为Leader,其余为follower
2. Producer只与Leader交互,把数据写入到Leader中
3. Followers从Leader中拉取数据进行数据同步
4. Consumer只从Leader拉取数据

ISR: 所有不落后的replica集合, 不落后有两层含义:
距离上次FetchRequest的时间不大于某一个值或落后的消息数不大于某一个值,

Leader失败后会从ISR中选取一个Follower做Leader

Replica Partition 拉取数据的过程

```scala
class ReplicaManager(val config: KafkaConfig,
    val replicaFetcherManager = new ReplicaFetcherManager(config, this, metrics, jTime, threadNamePrefix)
    // 和 leader 同步的数据
    val highWatermarkCheckpoints = config.logDirs.map(dir => (new File(dir).getAbsolutePath,
        new OffsetCheckpoint(new File(dir, ReplicaManager.HighWatermarkFilename)))).toMap

class ReplicaFetcherThread(name: String,
                           fetcherId: Int,
                           sourceBroker: BrokerEndPoint,
                           brokerConfig: KafkaConfig,
                           replicaMgr: ReplicaManager,

    // 定义如何处理拉取过来的数据
    def processPartitionData(topicAndPartition: TopicAndPartition, fetchOffset: Long, partitionData: PartitionData) {
        val replica = replicaMgr.getReplica(topic, partitionId).get
        val messageSet = partitionData.toByteBufferMessageSet
        replica.log.get.append(messageSet, assignOffsets = false)
        val followerHighWatermark = replica.logEndOffset.messageOffset.min(partitionData.highWatermark)
        replica.highWatermark = new LogOffsetMetadata(followerHighWatermark)
```

上面没有提到 Replica 的信息

```scala
class Replica(val brokerId: Int,
              val partition: Partition,
              time: Time = SystemTime,
              initialHighWatermarkValue: Long = 0L,
              val log: Option[Log] = None) extends Logging {

    var highWatermarkMetadata: LogOffsetMetadata
    var logEndOffsetMetadata: LogOffsetMetadata

```

### 数据可靠性保证

当Producer向Leader发送数据时,可以通过 acks 参数设置数据可靠性的级别

1. 0: 不论写入是否成功,server 不需要给 Producer 发送 Response, 如果发生异常, server会终止连接,触发Producer更新meta数据;
2. 1: Leader写入成功后即发送Response,此种情况如果Leader fail,会丢失数据
3. -1: 等待所有ISR接收到消息后再给Producer发送Response,这是最强保证
   仅设置acks=-1也不能保证数据不丢失,当Isr列表中只有Leader时,同样有可能造成数据丢失。要保证数据不丢除了设置acks=-1, 还要保 证ISR的大小大于等于2,具体参数设置:

1. request.required.acks: 设置为-1 等待所有ISR列表中的Replica接收到消息后采算写成功;
2. min.insync.replicas: 设置为大于等于2,保证ISR中至少有两个Replica

Producer 要在吞吐率和数据可靠性之间做一个权衡

消息发送到 broker 的过程

```scala
KafkaApis:
case RequestKeys.ProduceKey => handleProducerRequest(request)

handleProducerRequest:      
      replicaManager.appendMessages(
        produceRequest.ackTimeoutMs.toLong,
        produceRequest.requiredAcks,
        internalTopicsAllowed,
        authorizedRequestInfo,
        sendResponseCallback)

  def appendMessages(timeout: Long,
                     requiredAcks: Short,
                     internalTopicsAllowed: Boolean,
                     messagesPerPartition: Map[TopicAndPartition, MessageSet],
                     responseCallback: Map[TopicAndPartition, ProducerResponseStatus] => Unit) {

    val localProduceResults = appendToLocalLog(internalTopicsAllowed, messagesPerPartition, requiredAcks)

ReplicaManager:
private def appendToLocalLog(internalTopicsAllowed: Boolean,
    val partitionOpt = getPartition(topicAndPartition.topic, topicAndPartition.partition)
    // 根据 partition 找到 replica, 其实就是 broker 自己
    partition.appendMessagesToLeader(messages.asInstanceOf[ByteBufferMessageSet], requiredAcks)
        //val info = log.append(messages, assignOffsets = true) // parition.appendMessageToLeader

Partition 记录了自己的 Replica 和所有的 assignedReplicaMap
private val assignedReplicaMap = new Pool[Int, Replica]

Parition:
def appendMessagesToLeader(messages: ByteBufferMessageSet, requiredAcks: Int = 0) = {

    // Avoid writing to leader if there are not enough insync replicas to make it safe
    if (inSyncSize < minIsr && requiredAcks == -1) { throw new Exception

    val info = log.append(messages, assignOffsets = true)// log 是 partition 的 log
    // probably unblock some follower fetch requests since log end offset has been updated
    replicaManager.tryCompleteDelayedFetch(new TopicPartitionOperationKey(this.topic, this.partitionId))
    // we may need to increment high watermark since ISR could be down to 1
    (info, maybeIncrementLeaderHW(leaderReplica))

    // some delayed operations may be unblocked after HW changed
    if (leaderHWIncremented)
        tryCompleteDelayedRequests()
```

**关于 Purgatory, 也就是上面所说的缓冲池**





### 数据一致性保证

一致性定义:若某条消息对Consumer可见,那么即使Leader宕机了,在新Leader上数据依然可以被读到

1.HighWaterMark简称HW: Partition的高水位，取一个partition对应的ISR中最小的LEO作为HW，消费者最多只能消费到HW所在的位置，
  另外每个replica都有highWatermark，leader和follower各自负责更新自己的highWatermark状态，highWatermark <= leader. LogEndOffset
2.对于Leader新写入的msg，Consumer不能立刻消费，Leader会等待该消息被所有ISR中的replica同步后,更新HW,此时该消
  息才能被Consumer消费，即Consumer最多只能消费到HW位置

这样就保证了如果Leader Broker失效,该消息仍然可以从新选举的Leader中获取。对于来自内部Broker的读取请求,没有HW的限制。
同时,Follower也会维护一份自己的HW,Fellow.HW = min(Leader.HW, Follower.offset)

2016年10月20日 星期四 最新的理解

每个 ISR 成员都会尽力从 leader pull 数据， 更新自己的 leo, 然后 leader 还会广播 HW 到所有的 ISR, 让每个 ISR 更新自己的 hw,
当 leader crash 以后， ISR 中的成员因为没收到广播的 hw, 导致自己的 hw 比 leader 要低，这个时候会有问题。此外，消费者消费的数据不能比
HW 更高， 所以并没有冲突

### DS in zookeeper

**Broker registration info**
/brokers/ids/[brokerId]

```
Schema:
{ "fields":
    [ {"name": "version", "type": "int", "doc": "version id"},
      {"name": "host", "type": "string", "doc": "ip address or host name of the broker"},
      {"name": "port", "type": "int", "doc": "port of the broker"},
      {"name": "jmx_port", "type": "int", "doc": "port for jmx"}
      {"name": "endpoints", "type": "array", "items": "string", "doc": "endpoints supported by the broker"}
    ]
}
 
Example:
{
  "version":2,
  "host": "localhost",
  "port": 9092
  "jmx_port":9999,
  "timestamp": "2233345666",
  "endpoints": ["PLAINTEXT://host1:9092", "SSL://host1:9093"]
```

**ISR Change notification**  /isr_change_notification/isr_change_x

Gets created when ISR is changed at any broker, controller watches for these notifications and sends
MetadataUpdateRequest to all brokers.

**Client and Topic configuration overrides: The content of both znodes has the same structure**

/config/clients/[topic_name]
/config/topics/[topic_name]

```
{
  "version": 1,
  "config": {
    "config.a": "x",
    "config.b": "y",
    ...
  }
}
```
<<<<<<< HEAD

## Kafka延时分析

### 核心配置

**producer端: **

buffer.memory: 默认32m，每个producer实例可用来存储消息的最大内存空间（在实例中作为一个内存池存在）。 

retries; kafka默认0次, 异步发送失败重试次数。 

batch.size: 默认16k, 可以把一个batch.size大小的空间认为是一个槽。 

linger.ms: 默认0ms, 在异步IO线程被触发后（任何一个topic，partition满都可以触发），如果其他的

**broker端:**

replica.fetch.max.bytes: 默认1m，follower每次拉消息过程中，针对每个

**consumer端:**

fetch.message.max.bytes: 默认1m，consumer每次拉消息过程中，针对每个

kafka0.8 通过2个因素来控制ISR：1、最近追上的时间和当前时间的差和配置的阈值的比较。 2、replica partition和leader partition的消息条数的差和配置的阈值的比较。 

kafka0.9 抛弃了0.8中消息条数的控制，只通过最近追上的时间和当前时间的差和配置的阈值的比较来控制ISR的变化。 

LEO: 每个replica partition存储的最后一条消息的offset。 

HW(high water mark): partition的高水位，取这个partition对应的ISR中最小的LEO作为HW，消费者最多只能消费到HW所在的位置。

### 延时分析

这里不针对每种情况进行逐一分析，仅以一个非常具有代表性的case（异步发送，replica为3，ack为-1）来进行分析。

**4.1 producer**

针对每个producer实例： 

创建一个大小为buffer.memory的内存池，所有存放发送消息的缓存都是从这个内存池捞出来的空间。 

创建一个batches的Map，key为

**4.2 broker**

ack设置为0的情况下，类似于客户端进行了一次one way的rpc操作，不需要等待broker端的response。

针对ack为1和-1的情况，下面做些分析:

broker端接收到producer端发送过来的消息，先往leader partition上顺序写入这条消息，更新LEO和HW。 

针对ack为1的情况，直接response给Producer端。 

针对ack为-1的情况，创建一个延迟操作（DelayedProduce），延迟操作有个超时时间timeout.ms。

## Apache Kafka, Purgatory, and Hierarchical Timing Wheels
 
Apache Kafka has a data structure called the “request purgatory”. The purgatory holds 
any request that hasn’t yet met its criteria to succeed but also hasn’t yet resulted in an error. 
The problem is “How can we efficiently keep track of tens of thousands of requests that are 
being asynchronously satisfied by other activity in the cluster?”

Kafka implements several request types that cannot immediately be answered with a response. Examples:

* A produce request with acks=all cannot be considered complete until all in-sync replicas 
  have acknowledged the write and we can guarantee it will not be lost if the leader fails.
* A fetch request with min.bytes=1 won’t be answered until there is at least one new byte 
  of data for the consumer to consume. This allows a “long poll” so that the consumer need 
  not busy wait checking for new data to arrive.

These requests are considered complete when either (a) the criteria they requested is complete or (b) some timeout occurs.

### Old Purgatory Design

The request purgatory consists of a timeout timer and a hash map of watcher lists for event driven processing. 
A request is put into the purgatory when it is not immediately satisfiable because of unmet conditions. A request 
in the purgatory is completed later when the conditions are met or is forced to be completed (timeout) when it 
passed beyond the time specified in the timeout parameter of the request. In the old design, it used Java 
**DelayQueue** to implement the timer.

When a request is completed, the request is not deleted from the timer or watcher lists immediately. Instead, completed requests are deleted as they were found during condition checking. When the deletion does not keep up, the server may exhaust JVM heap and cause OutOfMemoryError.

To alleviate the situation, a separate thread, called the reaper thread, purges completed requests from the purgatory when the number of requests (either pending or completed) in the purgatory exceeds the configured number. The purge operation scans the timer queue and all watcher lists to find completed requests and deletes them.

By setting this configuration parameter low, the server can virtually avoid the memory problem. However, the server must pay a significant performance penalty if it scans all lists too frequently.

### New Purgatory Design

The goal of the new design is to allow immediate deletion of a completed request and reduce the load of expensive 
purge process significantly. It requires cross referencing of entries in the timer and the requests. Also it is 
strongly desired to have O(1) insert/delete cost since insert/delete operation happens for each request/completion.

A simple timing wheel is a circular list of buckets of timer tasks. Let u be the time unit. A timing wheel with size n has n buckets and 
can hold timer tasks in n * u time interval. Each bucket holds timer tasks that fall into the corresponding time range.

Every interval of time unit u, the timer ticks and moved to the next bucket then expire all timer tasks in it.
So, the timer never inserts a task into the bucket for the current time since it is already expired. The timer immediately runs the expired task.

A timing wheel has O(1) cost for insert/delete (start-timer/stop-timer) whereas priority queue based timers, 
such as java.util.concurrent.DelayQueue and java.util.Timer, have O(log n) insert/delete cost. Note that 
neither DelayQueue or Timer supports random delete.

A major drawback of a simple timing wheel is that it assumes that a timer request is 
within the time interval of n * u from the current time. If a timer request is out of this interval, it 
is an overflow. A hierarchical timing wheel deals with such overflows. It is a hierarchically organized 
timing wheels that delegate overflows to upper level wheels. The lowest level has the finest time resolution. 
Time resolutions become coarser as we move up the hierarchy. 

At each level overflows are delegated to the wheel in one level higher. When the wheel in the higher 
level ticks, it reinsert timer tasks to the lower level. An overflow wheel can be created on-demand.

When a bucket in an overflow bucket expires, all tasks in it are reinserted into the timer recursively. 
The tasks are then moved to the finer grain wheels or be executed. The insert (start-timer) cost is O(m) 
where m is the number of wheels, which is usually very small compared to the number of requests in 
the system, and the delete (stop-timer) cost is still O(1).

大小变为平方 nu ---> nnu

**Doubly Linked List for Buckets in Timing Wheels**

**Driving Clock using DelayQueue**

A simple implementation may use a thread that wakes up every unit time and does the ticking, 
which checks if there is any task in the bucket. 

The unit time of the purgatory is 1ms (u = 1ms). This can be wasteful if requests are sparse at the wheel at the lowest level. This is usually the case because the majority of requests are satisfied before inserted into the wheel at the lowest level. It would be nice if a thread wakes up only when there is a non-empty bucket to expire. The new purgatory does so by using java.util.concurrent.DelayQueue similarly to the old implementation, but we enqueue task buckets instead of individual tasks. This design has a performance advantage. The number of items in DelayQueue is capped by the number of buckets, which is usually much smaller than the number of tasks, thus the number of offer/poll operations to the priority queue inside DelayQueue will be significantly smaller.

**Purging Watcher Lists**

In the new design, a completed request is removed from the timer queue immediately with O(1) cost. It means that the number of requests in the timer queue is the number of pending requests exactly at any time. So, if we know the total number of distinct requests in the purgatory, which includes the sum of the number of pending request and the numbers completed but still watched requests, we can avoid unnecessary purge operations. It is not trivial to keep track of the exact number of distinct requests in the purgatory because a request may or may not be watched. In the new design, we estimate the total number of requests in the purgatory rather than trying to maintain the exactly number.

The estimated number of requests are maintained as follows:

1. The estimated total number of requests, E, is incremented whenever a new request is watched.
2. Before starting the purge operation, we reset the estimated total number of requests to the size of timer queue. This is the current number of pending requests. If no requests are added to the purgatory during purge, E is the correct number of requests after purge.
3. If some requests are added to the purgatory during purge, E is incremented to E + the number of newly watched requests. This may be an overestimation because it is possible that some of the new requests are completed and remove from the watcher lists during the purge operation. We expect the chance of overestimation and an amount of overestimation are small.


### Code

```scala
class TimerTaskList(taskCounter: AtomicInteger) extends Delayed
    private[this] val root = new TimerTaskEntry(null) // dummy header
    private[this] val expiration = new AtomicLong(-1L)
    
    // 每个桶是一个双向链表
    private[this] val buckets = Array.tabulate[TimerTaskList](wheelSize) { _ => new TimerTaskList(taskCounter) }
    
    // overflowWheel can potentially be updated and read by two concurrent threads through add().
    // Therefore, it needs to be volatile due to the issue of Double-Checked Locking pattern with JVM
    // 必须是两个么
    @volatile private[this] var overflowWheel: TimingWheel = null
    
  def foreach(f: (TimerTask) => Unit): Unit = {
    synchronized {
      var entry = root.next
      while (entry ne root) {
        val nextEntry = entry.next

        if (!entry.cancelled) f(entry.timerTask)

        entry = nextEntry
      }}}
  
  def getDelay(unit: TimeUnit): Long = {
    unit.convert(max(getExpiration - SystemTime.milliseconds, 0), TimeUnit.MILLISECONDS)
  }

  def add(timerTaskEntry: TimerTaskEntry): Unit = {
    var done = false
    while (!done) {
      // Remove the timer task entry if it is already in any other list
      // We do this outside of the sync block below to avoid deadlocking.
      // We may retry until timerTaskEntry.list becomes null.
      timerTaskEntry.remove()

      synchronized {
        timerTaskEntry.synchronized {
          if (timerTaskEntry.list == null) {
            // put the timer task entry to the end of the list. (root.prev points to the tail entry)
            val tail = root.prev
            timerTaskEntry.next = root
            timerTaskEntry.prev = tail
            timerTaskEntry.list = this
            tail.next = timerTaskEntry
            root.prev = timerTaskEntry
            taskCounter.incrementAndGet()
            done = true
          }}}}}
```

这里, 我不理解为什么 root.prev 指向的是最后一个节点, 双线链表的插入很简单, 删除更加简单, 因为 dummy header 的存在,
不需要做各种判断

List Entry

```scala
class TimerTaskEntry(val timerTask: TimerTask) {
  @volatile
  var list: TimerTaskList = null
  var next: TimerTaskEntry = null
  var prev: TimerTaskEntry = null
  def remove(): Unit = {
    var currentList = list
    // If remove is called when another thread is moving the entry from a task entry list to another,
    // this may fail to remove the entry due to the change of value of list. Thus, we retry until the list becomes null.
    // In a rare case, this thread sees null and exits the loop, but the other thread insert the entry to another list later.
    // 删除成功的话, currentList 会变成 null
    while (currentList != null) {
      currentList.remove(this)
      currentList = list
    }}
```

### 在 Kafka 中的应用

```
class Timer(taskExecutor: ExecutorService, tickMs: Long = 1, wheelSize: Int = 20, startMs: Long = System.currentTimeMillis) {
    private[this] val delayQueue = new DelayQueue[TimerTaskList]()
    private[this] val taskCounter = new AtomicInteger(0)
    private[this] val timingWheel = new TimingWheel(
        tickMs = tickMs,
        wheelSize = wheelSize,
        startMs = startMs,
        taskCounter = taskCounter,
        delayQueue)
        
    // Locks used to protect data structures while ticking
    private[this] val readWriteLock = new ReentrantReadWriteLock()
    private[this] val readLock = readWriteLock.readLock()
    private[this] val writeLock = readWriteLock.writeLock()
    
      private def addTimerTaskEntry(timerTaskEntry: TimerTaskEntry): Unit = {
        if (!timingWheel.add(timerTaskEntry)) {
          // Already expired or cancelled
          if (!timerTaskEntry.cancelled)
            taskExecutor.submit(timerTaskEntry.timerTask)
        }}
  /*
   * Advances the clock if there is an expired bucket. If there isn't any expired bucket when called,
   * waits up to timeoutMs before giving up.
   */
  def advanceClock(timeoutMs: Long): Boolean = {
    var bucket = delayQueue.poll(timeoutMs, TimeUnit.MILLISECONDS)
    if (bucket != null) {
      writeLock.lock()
      try {
        while (bucket != null) {
          timingWheel.advanceClock(bucket.getExpiration())
          bucket.flush(reinsert)
          bucket = delayQueue.poll()
        }} finally {
        writeLock.unlock()}
      true
    } else {
      false
    }}
```

Poll data from DelayQueue

```scala
  private class ExpiredOperationReaper extends ShutdownableThread("ExpirationReaper-%d".format(brokerId), false) {

    override def doWork() {
      timeoutTimer.advanceClock(200L)

      // Trigger a purge if the number of completed but still being watched operations is larger than
      // the purge threshold. That number is computed by the difference btw the estimated total number of
      // operations and the number of pending delayed operations.
      if (estimatedTotalOperations.get - delayed > purgeInterval) {
        // now set estimatedTotalOperations to delayed (the number of pending operations) since we are going to
        // clean up watchers. Note that, if more operations are completed during the clean up, we may end up with
        // a little overestimated total number of operations.
        estimatedTotalOperations.getAndSet(delayed)
        debug("Begin purging watch lists")
        val purged = allWatchers.map(_.purgeCompleted()).sum
        debug("Purged %d elements from watch lists.".format(purged))
      }}}


class DelayedOperationPurgatory[T <: DelayedOperation](purgatoryName: String, brokerId: Int = 0, purgeInterval: Int = 1000)
  private[this] val timeoutTimer = new Timer(executor)
  
  /* a list of operation watching keys */
  private val watchersForKey = new Pool[Any, Watchers](Some((key: Any) => new Watchers(key)))
  
  /* background thread expiring operations that have timed out */
  private val expirationReaper = new ExpiredOperationReaper()
  expirationReaper.start()
```

?要求达到时, 怎么从 TimingWheel 中删除元素??

### Produce Delayed operation

```scala
DelayedProduce:
    * Case A: This broker is no longer the leader: set an error in response
    * Case B: This broker is the leader:
    *   B.1 - If there was a local error thrown while checking if at least requiredAcks
    * replicas have caught up to this operation: set an error in response
    *   B.2 - Otherwise, set the response with no error.
    */
  override def tryComplete(): Boolean = {
    // check for each partition if it still has pending acks
    produceMetadata.produceStatus.foreach { case (topicAndPartition, status) =>
      // skip those partitions that have already been satisfied
      if (status.acksPending) {
        val partitionOpt = replicaManager.getPartition(topicAndPartition.topic, topicAndPartition.partition)

        val (hasEnough, errorCode) = partitionOpt match {
          case Some(partition) => partition.checkEnoughReplicasReachOffset(status.requiredOffset)
          case None =>
            // Case A
            (false, ErrorMapping.UnknownTopicOrPartitionCode)
        }

        if (errorCode != ErrorMapping.NoError) {
          // Case B.1
          status.acksPending = false
          status.responseStatus.error = errorCode
        } else if (hasEnough) {
          // Case B.2
          status.acksPending = false
          status.responseStatus.error = ErrorMapping.NoError
        }}}

    // check if each partition has satisfied at lease one of case A and case B
    if (!produceMetadata.produceStatus.values.exists(p => p.acksPending)) forceComplete()
    else false}
    
Partition:
  def checkEnoughReplicasReachOffset(requiredOffset: Long): (Boolean, Short) = {
    leaderReplicaIfLocal() match {
      case Some(leaderReplica) =>
        // keep the current immutable replica list reference
        val curInSyncReplicas = inSyncReplicas

        // 复制的结果
        val numAcks = curInSyncReplicas.count(r => {
          if (!r.isLocal)
            if (r.logEndOffset.messageOffset >= requiredOffset)   true
            else false
          else true /* also count the local (leader) replica */
        })

        val minIsr = leaderReplica.log.get.config.minInSyncReplicas

        // 为什么 hw 会大于 required offset 呢
        if (leaderReplica.highWatermark.messageOffset >= requiredOffset ) {
          /*
          * The topic may be configured not to accept messages if there are not enough replicas in ISR
          * in this scenario the request was already appended locally and then added to the purgatory before the ISR was shrunk
          */
          if (minIsr <= curInSyncReplicas.size) {
            (true, ErrorMapping.NoError)
          } else {
            (true, ErrorMapping.NotEnoughReplicasAfterAppendCode)
          }
        } else
          (false, ErrorMapping.NoError)
      case None =>
        // 操作一定是在 leader 完成的
        (false, ErrorMapping.NotLeaderForPartitionCode)
    }
  }
```

问题有很多:

1. Replica 的作用是什么, 为什么 log 是 Replica 的成员变量而不是 Partition 的
2. 为什么 endoffset 是由 replica 来管理
3. leader 知道所有的 replica 信息, 包括 endoffset, 这个信息是怎么传过来的, zookeeper 么?
4. 为什么 hw 会大与 required offset 呢?

### DelayedFetch 实现

```scala
    * Case A: This broker is no longer the leader for some partitions it tries to fetch
    * Case B: This broker does not know of some partitions it tries to fetch
    * Case C: The fetch offset locates not on the last segment of the log
    * Case D: The accumulated bytes from all the fetching partitions exceeds the minimum bytes
    *
    * Upon completion, should return whatever data is available for each valid partition
    */
  override def tryComplete(): Boolean = {
    var accumulatedSize = 0

    // 获取实时的是元数据, 当元数据完毕 ready 以后, 才会真正的去 poll data, 见下面的 onComplete
    fetchMetadata.fetchPartitionStatus.foreach {
      case (topicAndPartition, fetchStatus) =>
        val fetchOffset = fetchStatus.startOffsetMetadata
        
        try { // 这里并没有看懂
          if (fetchOffset != LogOffsetMetadata.UnknownOffsetMetadata) {
            val replica = replicaManager.getLeaderReplicaIfLocal(topicAndPartition.topic, topicAndPartition.partition)
            val endOffset =
              if (fetchMetadata.fetchOnlyCommitted) replica.highWatermark // 专用于 consumer?
              else replica.logEndOffset

            if (endOffset.offsetOnOlderSegment(fetchOffset)) {
              // Case C, this can happen when the new fetch operation is on a truncated leader
              debug("Satisfying fetch %s since it is fetching later segments of partition %s."
                .format(fetchMetadata, topicAndPartition))
              return forceComplete()
            } else if (fetchOffset.offsetOnOlderSegment(endOffset)) {
              // Case C, this can happen when the fetch operation is falling behind the current segment
              // or the partition has just rolled a new segment
              debug("Satisfying fetch %s immediately since it is fetching older segments.".format(fetchMetadata))
              return forceComplete()
            } else if (fetchOffset.precedes(endOffset)) {
              // we need take the partition fetch size as upper bound when accumulating the bytes
              accumulatedSize += math.min(endOffset.positionDiff(fetchOffset), fetchStatus.fetchInfo.fetchSize)
            }
          }
        } catch {
          case utpe: UnknownTopicOrPartitionException => // Case B
            debug("Broker no longer know of %s, satisfy %s immediately".format(topicAndPartition, fetchMetadata))
            return forceComplete()
          case nle: NotLeaderForPartitionException => // Case A
            debug("Broker is no longer the leader of %s, satisfy %s immediately".format(topicAndPartition, fetchMetadata))
            return forceComplete()
        }
    }
    // Case D
    if (accumulatedSize >= fetchMetadata.fetchMinBytes) forceComplete()
    else false
  }
```

同样的问题, Replica 的更新是怎么让 Leader 知道的, 查看 KafkaApis
