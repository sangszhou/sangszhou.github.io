---
layout: post
title: Spring aspectj and distributed tracing system
categories: [java]
description: java
keywords: java, thread
---

这几天研究了下分布式追踪系统，希望能在 team 中使用到这种技术，它本身是一个很有效的工具，但是复杂性较高，我觉得很难搬来放到我们的场景。下面是对这几天学习的总结。

大的系统有数以百计的分布式服务构成，每一个请求路由过来以后，会经过多个业务系统并留下足迹，并产生对各种 cache 和 DB 的访问，但是这些分散的数据对于问题排查，或者流程优化都有限。对于一个跨进程、线程的场景，汇总收集并分析海量日志就显得尤为重要。要做到追踪每个请求的完整调用链路，收集调用链路上每个服务的性能数据，计算性能数据和对比性能指标，甚至在更远的未来能够再反馈到服务治理中，那么这就是分布式跟踪的目标了。在业界，twitter 的 zipkin 和淘宝的鹰眼就是类似的系统，他们都起源于 Google dapper。

Google 叫做 Dapper, 淘宝叫鹰眼，Twitter 叫做 Zipkin, 京东商城叫做 Hydra, ebay 叫做 Centralized activity logging(CAL), 大众点评叫做 CAT。这样的系统通常有几个设计目标：

1. 低侵入性 ---- 作为非业务组件，应当尽量减少进入或者无侵入其他业务系统，对于使用放透明，减少开发人员的负担
2. 灵活的应用策略 --- 最好能够随时决定所收集数据的范围和粒度
3. 时效性 --- 从数据的收集和产生，到数据计算和处理，再到最终展现，都要求尽可能的快
4. 决策支持 --- 能够再决策支持层面发挥作用
5. 可视化

### 淘宝鹰眼是如何实现的

同一请求的所有相关调用的情况，在淘宝 Eagle Eye 里称作调用链。同一时刻某一台服务器并行发起的网络调用有很多，怎么识别这些调用时属于哪一个调用练呢？可以在各个发起网络调用的中间件下手。

在前端请求到达服务器时，应用容器在执行实际业务处理之前，会先执行 EagleEye 的埋点逻辑 (类似 Filter 的机制), 埋点逻辑为这个前端请求分配一个全局唯一的调用链ID。这个ID在 EagleEye 里面被称为 TraceId，埋点逻辑把 TraceId 放在一个调用上下文对象里面，而调用上下文对象会存储在 ThreadLocal 里面。调用上下文里还有一个ID非常重要，在 EagleEye 里面被称作 RpcId。RpcId 用于区分同一个调用链下的多个网络调用的发生顺序和嵌套层次关系。对于前端收到请求，生成的 RpcId 固定都是0。

当这个前端执行业务处理需要发起 RPC 调用时，淘宝的 RPC 调用客户端 HSF 会首先从当前线程 ThreadLocal 上面获取之前 EagleEye 设置的调用上下文。然后，把 RpcId 递增一个序号。在 EagleEye 里使用多级序号来表示 RpcId，比如前端刚接到请求之后的 RpcId 是0，那么 它第一次调用 RPC 服务A时，会把 RpcId 改成 0.1。之后，调用上下文会作为附件随这次请求一起发送到远程的 HSF 服务器。

HSF 服务端收到这个请求之后，会从请求附件里取出调用上下文，并放到当前线程 ThreadLocal 上面。如果服务A在处理时，需要调用另一个服务，这个时候它会重复之前提到的操作，唯一的差别就是 RpcId 会先改成 0.1.1 再传过去。服务A的逻辑全部处理完毕之后，HSF 在返回响应对象之前，会把这次调用情况以及 TraceId、RpcId 都打印到它的访问日志之中，同时，会从 ThreadLocal 清理掉调用上下文。如图6-1展示了一个浏览器请求可能触发的系统间调用。

![](/images/posts/web/eagleEye.png)

![](/images/posts/web/eagleeye_archi.png)

图描述了 EagleEye 在一个非常简单的分布式调用场景里做的事情，就是为每次调用分配 TraceId、RpcId，放在 ThreadLocal 的调用上下文上面，调用结束的时候，把 TraceId、RpcId 打印到访问日志。类似的其他网络调用中间件的调用过程也都比较类似，这里不再赘述了。访问日志里面，一般会记录调用时间、远端IP地址、结果状态码、调用耗时之类，也会记录与这次调用类型相关的一些信息，如URL、服 务名、消息topic等。很多调用场景会比上面说的**完全同步的调用更为复杂**，比如会遇到异步、单向、广播、并发、批处理等等，这时候需要妥善处理好 ThreadLocal 上的调用上下文，避免调用上下文混乱和无法正确释放。另外，采用多级序号的 RpcId 设计方案会比单级序号递增更容易准确还原当时的调用情况。


### 京东如何实现的

京东商城引入了阿里开源的服务治理中间件 Dubbo，所以它的分布式跟踪 Hydra 基于 Dubbo 就能做到对业务系统几乎无侵入了。Hydra 的领域模型如下图7所示

![](/images/posts/web/jd_hydra.png)

![](/images/posts/web/hydra_archi.png)


### 窝窝如何实现的

![](/images/posts/web/wowo_trace_code.png)

埋点:

1. 实现线程内 trace 上下文传递，即服务器内部的方法互调时不需要强制在方法形参中加 Message 参数
2. 实现 trace 埋点逻辑自动织入功能，即业务开发人员不需要在方法中打印 trace 日志，只需要给该方法加注解标识

利用 javaagent 原理，执行 main 方法以前会先执行 premain 方法，在该方法内将字节码转换器载入 instrument, 而后 JVM 在加载 class 文件之前都会先执行改 字节码转换器

字节码转换器的逻辑为，识别出注解为 trace 的类和方法，并修改该方法的字节码，织入埋点逻辑。进入方法时会初始 trace 上下文信息，并存储在先传给的 ThreadLocal 中，退出会打印 trace 日志并清空该方法的上下文

## 技术和难点总结

分布式追踪的关键名词就是 trace 和 span, 其中 trace 是指从 client 发出请求到收到返回的整个流程，它可能贯穿整个系统，多个 service. 另一个是 span, 它是指一次 rpc 或者 http request, 表示一次远程调用，一个 trace 下会有很多的 span, span 之间有父子关系和兄弟关系，
就像上面的 eagle eye 图上展示的一样。

**span 的传递:**

distributed span 最难的地方在于，如何传递 span, 让 span 能够知道自己的 parent span 是谁。在弄明白几个系统后就会发现这里并没有什么高大上的技术在里面，而是使用很朴素的做法：枚举出所有可能产生 rpc call 的方式，然后把 span id 传到下游，下游收到请求后取出 span id，记录一下，再往下传递。

目前产生 RPC call 的方式有三种，第一种是 Http (Rest), 第二种是 Rpc framework, 第三种是 Queue. 如果某个 service 通过 Http 调用另一个 service, 那个系统会在 Http service 中注入 traceid 和 spanid, spanid 传到下游后如果下游支持 distributed tracing, 就会取出 traceid 和 spanid 然后放到 context 信息中。RPC 的方式道理类似，因为 RPC framework 往往是公司内部维护，所以它的灵活性要比 Htp request 更好，协议想怎么定就怎么定。第三种方式我倒没在别的系统中见过，但是在我的 team, 消息都是这么传递的，我们深度依赖 kafka 作为消息传递的方式，当然也有很多 Http 的请求。我想，思路应该是一样的，往 kafka 写入消息时只要把两个元信息也附上就可以了。技术上的确没什么难点，但是肯定要做很多工作。

**trace id, span id 的获取**

上面有提到 distributed tracing 要求侵入性要低，用户尽可能少的写 tracing 相关的代码，在最差的情况下记一段就像写一个 log 一样简单，假如看到某个系统需要用户写 trace.start() trace.finish() 两段代码，这个系统可能还有优化的空间。目前 zipkin 是要记录开始和结束的，CAT 似乎不需要记录 transaction 的结束的。

创建 trace 和 span 的方式要么是通过静态类型调用 create 方法创建的，要么是使用 autowired 参数



```java
@Autowired RestTemplate restTemplate;
// 从哪 wire 进来的？
@Autowired Tracer tracer;
Span span = this.tracer.createSpan("first_span");
```

使用 autowired 的对象是因为这些对应已经被织入了捕捉 span 信息的逻辑，**织入的方式可能是使用 aspectj，也可以使用对原始类型的封装**，这两种方式各有利弊，后面再分析

这些系统无一例外都是把 trace id, span id 信息写到 ThreadLocal 中的

```java
class SpanContextHolder {
    private static final ThreadLocal<SpanContext> CURRENT_SPAN = new NamedThreadLocal<>("Trace Context");
    
    static Span getCurrentSpan() { return isTracing() ? CURRENT_SPAN.get().span : null;}
}
```

SpanContextHolder add span 时是可以检测到 span 的父子关系的，它会对一个 service 之中有父子关系的 span 进行压缩，减小最后统计的压力（？不确定）

createTrace 之前会先到 ThreadLocal 里看一眼是否已经存在 span 信息了，如果已经存在了如果有的话，那么就发现了一个 Service 内部的父子关系。


**异步怎么办?**

刚才说到了 ThreadLocal, 而 ThreadLocal 最大的问题是对异步调用就无能为力了，普通的 spring 代码或者 java 代码还好，异步用的比较少，且 spring slueth 已经通过 annotation 提供了对 Callable 和 Runnable 的异步调用支持，我觉得它的实现应该就是动态代理，把 span 信息注入到了对象中，run 返回时再调用 span 的 close 方法。要注意的是最好要清理 ThreadLocal. 

但是我们的一个核心服务是 scala 写的，里面有大量的异步代码，举个例子

```scala
for (food <- foodStore;
    drink <- drinkStore) yield (food, drink)
```

这一段代码就发起了两个异步调用，这个真是无能为力了，还好 kamon 给出了一个解法，解法并不优雅，必须让用户写一个 Trace 把 Future 的东西全部包起来，这样才能保证 context 在 future 里依然 propogate, 具体的实现原理我还想不出，也没有看源码了解它到底是怎么实现的

**收集 trace**

zipkin 是这样的，每个 client 会把 trace 信息发到 rabbitmq 或者 kafka 中，zipkin server 从 queue 中读取信息，分析数据，并把数据写到持久层，持久层在测试环境下可以使用 inMem 模式，常用的持久层还有 mysql, cassandra, elasticsearch 等等

## 应用 distributed tracing 的可能性

### survey

上面已经说了一部分业界比较前沿的 distributed tracing 系统，除此之外还有 google dataflow, 它提供了 trace 功能，可以在图上看到 pipeline 上每个 component 的使用信息，2014 年我在 google I/O 大会上第一次看到这个图激动的不行。和 scala 比较近的一个 trace 收集工具叫做 kamon, 去年用过一段时间感觉这个工具对性能影响太大，本来一个 spray server 5 秒就起来了，用了 kamon 以后启动要花 30 秒以上，就弃用了。我看到 kamon 多了很多包，比如 kamon-elasticsearch, kamon-jdbc, 这些包都是通过 aspectj 织入 trace 信息，然后再把收集到的 trace 添加到 TraceContext 中，最后持久化这些信息。

Twitter 的 zipkin 开源后叫做 open zipkin, github 里可以查看的到，代码是 java 编译工具是 maven, 我想在 twitter 内部，zipkin 肯定是 scala + sbt 的项目。open zipkin 已经足够好了，但是 spring cloud 又给出了比它更好的解决方案，slueth, 首先 slueth 是基于 zipkin 的，用作者的话说就是 borrow heavily from zipkin。它做的额外工作是和 spring cloud 集成，让用户不必写代码就能构建出 spring cloud microservice 之间的调用关系，当然需要更细的调用关系的话，就得手写 span 了。

**我们的场景: ** 以 storm 为基础的 ETL 系统，我们本来是用 storm 做 ETL 的，但是写了很多代码后觉得有进一步抽象的空间，首先用户不一定要知道 backbone 是 storm, 不需要用户写 bolt 或者 spout, 用户只需要用配置文件声明数据的来源，数据就会源源不断的到来，在此基础上做 transform 也只需要写处理逻辑，不需要和 bolt 有任何关系，处理逻辑最后会 attach 到 storm 上，最后声明数据的存储地点，数据就会放进去了。我觉得目前你的设计虽然不需要知道 bolt 或者 spout 还是需要知道 fetcher, dumper, parser, 我觉得更好的一种解法是像 google dataflow 那样，完全不用管背后的逻辑，只需要写一个 pipeline 一样

```java
    input
        // row... => <station route, station speed> ...
        .apply(ParDo.of(new ExtractStationSpeedFn()))
        // map the incoming data stream into sliding windows.
        // The default window duration values work well if you're running the accompanying Pub/Sub
        // generator script without the --replay flag, so that there are no simulated pauses in
        // the sensor data publication. You may want to adjust the values otherwise.
        .apply(Window.<KV<String, StationSpeed>>into(SlidingWindows.of(
            Duration.standardMinutes(options.getWindowDuration())).
            every(Duration.standardMinutes(options.getWindowSlideEvery()))))
        .apply(new TrackSpeed())
        .apply(BigQueryIO.Write.to(tableRef)
            .withSchema(FormatStatsFn.getSchema()));
```

我觉得 google dataflow 的写法也比较奇怪，但是一旦写习惯了应该就就接受了。上面的代码是我想要的样子，我觉得一个 ETL 就应该写成这样，完全不用关心底层的实现，背后可以是 spark, flink, google dataflow.

### Tryout

**CAT** 的文档很少，文档中并没有找到怎么使用的例子，成功起来一个 Server 又写了一个 client, 但是 client 的数据就是就发不到 server 上，dashboard 上的数据总是空的，我看 client 的 applogs 看起来也是对的，server 显示连接成功，但就是连不上。之前安装 server 的时候也遇到一个 mysql 创建 mysql table 失败的问题，两个问题加起来让我感觉很失望，我就不打算再尝试了。我觉得既然开源就要做的像个样子，开源出来代码又维护不力是在浪费彼此的时间。

**Zipkin & Spring cloud sleuth**

spring 的东西我是比较放心的，一般跑起来是肯定没问题的，spring cloud 作为一个比较新的分支，与老的 spring 项目比起来文档还是少，假如只想使用而不是读源码的话，也够用了。我用的是一个叫做 spring documentation apps 这个 demo。Demo 上有 4 个 service, 1 个 zipkin server, service 上的收集的数据通过 rabbitmq 发到 zipkin server. rabbitmq 的安装需要 docker 环境，启动的时候第一个 service 有点问题，service 2,3,4 都是正常的，rabbitmq 每次重启系统都会删除再创建所以它肯定不会成为问题。rabbitmq 提供 rest management portal, docker 也把这个端口暴露出来了，可以协助 debug. 在 zipkin 上看到 service 之间的调用逻辑，图非常简单的，只有数据的流向关系并没有统计信息，也没有 log 相关的东西。相比于 CAT 的 Dashboard 显得有些寒酸。

**Kamon**

kamon 是一个 monitor tool 而不是 distributed tracing system, 但是 kamon 专注于 scala 项目的监控，这正是我们场景所需要的，我去年就用过 kamon, 但是感觉有点 heavy, 用了之后 spray server 的启动速度变慢了很多，但是 spray 的思想对项目还是有很大的启发，包括监控异步调用以及 elasticsearch 和 jdbc，监控 metrics 的数据结构。

其他的系统我就没有机会尝试了，没有资源或者还没有 ready。 apache beam 就是那个还没有 ready 的项目，不过看起来非常 promising.


### AOP & Storm

在看完这些系统后，我觉得没有一个能在我的场景里直接用上的，所以我觉得应该我应该写一个 demo, 把自己遇到的问题都解决一下。要解决这些问题，肯定会用到 AOP，所以我写了一个简单的例子，用 spring aop 来拦截方法，再通过 around annotation 记录消息内容以及时间信息。spring aop 的例子在 [](add_later)

考虑到程序以后可能会放到 Storm 上跑，我又写了个一 demo 程序，把 spring aop 和 storm 拼成一起的项目放到 storm 上 run, 提交 storm job 以前我现在本地跑了一遍，发现跑不通，看来 storm 和 spring aop/context 没法一起用了，因为我现在还不了解 storm jar 在 storm cluster 的执行方式，这样 spring 容器很可能就有问题，所以通过 spring context 试下 AOP 看起来是不可能了。所以，只能用 aspectj 手动替换 .class 文件了。

在写完被织入代码和织入代码后，aspectj 可以手动织入创建新的 .class, 但是手动就太麻烦了，看到有人说 aspectj 可以使用 maven plugin 完成织入过程，它的实现原理是在 post compile phase 完成织入。不但可以对 .class 织入，还可以对 jar 织入代码。我觉得这个功能很强大，正是我想要的，但是尝试了这个插件缺发现不 work, 我想肯定是哪个地方又不 work, 网上的资料也不多。正好这个时候和同事讨论，同事觉得使用 aspectj 有一定的危险性。我觉得有道理就没继续尝试下去。

**Pros and Cons of Aspectj**

为了方便开发者，我觉得不应该在系统内让用户手动 create new span; complete span. backbone 应该把这部分工作完成，除非用户真的是想监控某个方法，它可以手动做一些事。实现这个目的的方法就是让用户使用我们提供给他的各种 service, 比如 Http request, Elasticsearch request 等等。这些 service 可以通过注入的方式让用户拿到，用户拿到的 instance 都是被注入了监控代码的，这样用户只要调用某个方法都会被收集到 metrics, 再结合 context 信息就能拿到一个这个请求的上下文。注入监控代码的方式有两种，第一种就是 aspectj, 这种方式的好处是需要些的代码量比较少，因为一些大部分库的 public 方法往往只会调用一个底层的 private/protected 方法，只要拦截这个底层方法就好了。第二个办法是 wrap 这些库，重写 public 方法，然后提供给用户，这个方法工作量就比较大了，因为 public 方法比较多，并且这些工作往往是重复性的工作。

Aspectj 的 cons 有 1: 假如 storm 用了某些库也被织入过了代码，那么就可能出现记录了系统的 metric 现象，这种方式不太好。2: elasticsearch 是使用 rest template 封装的, http 请求也是使用 rest template 的，假如只织入 rest template 代码，那么 elasticsearch 的访问数据需要再次解析，但是如果两个都织入又会出现重复计算。2: 替换 .class 文件有些复杂，不好控制，没人是这方便的专家。

最终，决定使用 wrap 的方式来做，这样更加安全一些。

### 关于 tracing demo

Storm 的线程模型不是我们控制的了的，它由 storm 本身来托管，系统之间又是靠 kafka 之间传递消息的，最重要的 component 代码大部分都是异步的，这使得 tracing 变得异常困难，关于 tracing 在系统的使用只能无限期推迟了。很可能无法在我们 team 实现。