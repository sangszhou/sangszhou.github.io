谈谈对上下文切换的理解，我发现几个工作 7，8 年的人， 对 CPU 和线程之间的关系理解不清。下面从几个角度来分析，首先是

1. 什么是上下文切换
2. NIO 和上下文切换的关系


### 上下文切换

即使是单核CPU也支持多线程执行代码，CPU通过给每个线程分配CPU时间片来实现这个机制。时间片是CPU分配给各个线程的时间，因为时间片非常短，所以CPU通过不停地切换线程执行，让我们感觉多个线程时同时执行的，时间片一般是几十毫秒（ms）。

CPU通过时间片分配算法来循环执行任务，当前任务执行一个时间片后会切换到下一个任务。但是，在切换前会保存上一个任务的状态，以便下次切换回这个任务时，可以再次加载这个任务的状态，从任务保存到再加载的过程就是一次上下文切换。

```java
public class ContextSwitchTest
{
    private static final long count = 10000;
    
    public static void main(String[] args) throws Exception {
        concurrency();
        serial();
    }
    
    private static void concurrency() throws Exception {
        long start = System.currentTimeMillis();
        Thread thread = new Thread(new Runnable(){
            public void run()
            {
                int a = 0;
                for (int i = 0; i < count; i++)
                {
                    a += 5;
                }
            }
        });
        thread.start();
        int b = 0;
        for (long i = 0; i < count; i++)
        {
            b --;
        }
        thread.join();
        long time = System.currentTimeMillis() - start;
        System.out.println("Concurrency：" + time + "ms, b = " + b);
    }
    
    private static void serial() {
        long start = System.currentTimeMillis();
        int a = 0;
        for (long i = 0; i < count; i++)
        {
            a += 5;
        }
        int b = 0;
        for (int i = 0; i < count; i++)
        {
            b --;
        }
        long time = System.currentTimeMillis() - start;
        System.out.println("Serial：" + time + "ms, b = " + b + ", a = " + a);
    }
}
```

```
循环次数	串行执行耗时/ms	并发执行耗时/ms	串行和并发对比
1亿	78	50	并发快约0.5倍
1000万	10	6	并发快约0.5~1倍
100万	3	2	差不多
10万	2	2	差不多
1万	0	1	差不多，十几次执行下来，总体而言串行略快
```

在上面的例子中，可以看出来，当循环次数多的时候，并发的效果更好，而循环次数少的时候，创建线程的 Overhead 就大了。其实这个例子并不好，线程切换一次并没有什么 overhead, 且这个例子并没有线程上下文切换，只是创建了一个新线程而已。（假设 CPU 的 core 数大于 1）

在三种情况下可能会发生上下文切换：**中断处理**，**多任务处理**，**用户态切换**。在中断处理中，其他程序”打断”了当前正在运行的程序。当CPU接收到中断请求时，会在正在运行的程序和发起中断请求的程序之间进行一次上下文切换。在多任务处理中，CPU会在不同程序之间来回切换，每个程序都有相应的处理时间片，CPU在两个时间片的间隔中进行上下文切换。对于一些操作系统，当进行用户态切换时也会进行一次上下文切换，虽然这不是必须的。

**引起上下文切换的原因**

1. 时间片用完，CPU正常调度下一个任务
2. 被其他优先级更高的任务抢占
3. **执行任务碰到 IO 阻塞**，调度器挂起当前任务，切换执行下一个任务
4. 用户代码主动挂起当前任务让出CPU时间
5. 多任务抢占资源，由于没有抢到被挂起
6. 硬件中断


线程是由CPU进行调度的，CPU的一个时间片内只执行一个线程上下文内的线程，当CPU由执行线程A切换到执行线程B的过程中会发生一些列的操作，这些操作主要有”保存线程A的执行现场“然后”载入线程B的执行现场”，这个过程称之为“上下文切换（context switch）”,这个上下文切换过程并不廉价，如果没有必要，应该尽量减少上下文切换的发生。

在Linux中可以使用vmstat来观察上下文切换的次数，一般来说，空闲的系统，每秒上下文切换次数大概在1500以下。


**如何减少上下文切换**

既然上下文切换会导致额外的开销，因此减少上下文切换次数便可以提高多线程程序的运行效率。减少上下文切换的方法有无锁并发编程、CAS算法、使用最少线程和使用协程。

1. **无锁并发编程** 多线程竞争时，会引起上下文切换，所以多线程处理数据时，可以用一些办法来避免使用锁，如将数据的ID按照Hash取模分段，不同的线程处理不同段的数据
2. **CAS算法** Java的Atomic包使用CAS算法来更新数据，而不需要加锁
3. **使用最少线程** 避免创建不需要的线程，比如任务很少，但是创建了很多线程来处理，这样会造成大量线程都处于等待状态
4. **协程** 在单线程里实现多任务的调度，并在单线程里维持多个任务间的切换


可能使用**异步**也能减少上下文切换吧。

一个例子，说明上下文切换的问题就是 OceanBase 的任务队列 libeasy

UpdateServer 最初的任务模型基于淘宝的 Tbnet. Tbnet 封装的很好，使用比较方便，每秒收包个数最多可以达到 10W 个，不过仍然无法发挥 UpdateServer 收发小数据包以及内存服务的特点。OceanBase 后来采用优化过的任务模型 Libeasy, 小数据包处理能力得到进一步的提升。

Tbnet 队列模型本质上是一个生产者消费者队列模型，有两个线程：网络读写线程以及超时检查线程，其中网络读写线程执行事件循环，当服务器端有可读事件时，调用毁掉函数读取请求数据包，生成请求任务，并加入到任务队列中。工作线程从任务队列中检查任务，处理完成后触发可写任务，网络读写线程会将处理结果发给客户端，超时检查线程用于将超时的请求移除。

Tbnet 模型的问题在于多个工作线程从任务队列获取任务需要加锁互斥，这个过程将产生大量的上下文切换，测试发现，当 UpdateServer 每秒处理包的数量超过 8W 个时，UpdateServer 每秒的上下文切换次数接近 30W, 测试环境中，这已达到极限。（这个时候可能不适合用无锁队列，因为冲突实在太多，CAS 可能会使用大量的 CPU）

为了解决收发小数据包带来的上下文切换问题，OceanBase 采用 Libeasy 任务模型，Libeasy 采用多个线程收发包，增强了网络收发能力，每个线程收到网络包以后立即处理，减少了上下文切换。（这不就和 netty 一样了么，Netty 也是网络读写线程自己处理消息）



### NIO

有些人认为，blocking 会占用 CPU, 比如说读取 Networking 或者 JDBC 或者文件的时候，线程会阻塞，不会放 CPU。如果这样理解的话，线程状态的 Wait IO 在什么情况下会发生呢? 可能永远不会发生了，所以 Blocking IO 是不会占用 CPU 资源的，只会占用线程资源，如果线程资源充分，不可能有问题。

第二点是，使用 Future 修饰就是 NIO 了么？首先，大量的使用 Future 会带来上下文切换，因为 CPU 个数有限，使用 Future 可能会引用到另外的线程，虽然是 ForkJoinThreadPool 可以在一定程度上解决这个问题。其次，Future 就是 Non-blocking 的，对于当前线程来讲，Future 不会阻塞当前线程的执行。但是从整个系统CPU MEM的层面来讲，Future 没有带来好的效果，但是并发的角度来讲，可能会好一些。

我们使用 NIO 实现的 ES, MONGO client 有什么好处呢？ES client 返回的东西是 Future 包裹的东西，可能 ES client 的很多 API 允许添加 Listener, Listener 就是回调函数，而异步的实现就是回调函数。假如调用 ES 的请求特别多，假设有 10W 个，我们肯定不能创建 10W 个线程，可能创建 10 个吧，而 NIO 上最多只能同时注册 10 个时间，但是 NIO 一般来讲，可以注册的事件几千个是没问题的，这就是资源浪费。假设使用异步或者说是回调的方式，还是 10 个线程，这 10 个线程把 Request 发到 ES client 注册好回调内容后就返回，这样线程就可以被重用了，最终可以使数千个请求都放到 NIO 那里，好处是省下了线程，还是和 CPU 的关系并不是特别大。甚至说，可能线程是从一个 blockingQueue 中获取消息的，这会加剧 CPU 的使用量。

