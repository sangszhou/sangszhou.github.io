## Inverted index 

### 词条频度(Term Frequency)
    
词条在当前文档中出现的有多频繁？越频繁的话，那么权重就越高。在一个字段中出现了5次的词条应该
比只出现了1次的文档更加相关。词条频度通过下面的公式进行计算：

```
tf(t in d) = √frequency
```

### 倒排文档频度(Inverse Document Frequency)
    
词条在所有的文档中出现的频繁吗？出现的越频繁，权重就越低。像and或者the这样的常见
词条对相关度的贡献几乎没有，因为它们在绝大多数的文档中都会出现，而像elastic或者hippopotamus这样的
罕见词条则能够帮助找到我们最感兴趣的文档。倒排文档频度的计算方法如下：

```
idf(t) = 1 + log ( numDocs / (docFreq + 1))
```

### 字段长度归约(Field-length Norm)
    
字段的有多长？字段越短，那么其权重就越高。如果一个词条出现在较短的字段，如title字段中，那么该字
段的内容相比更长的body字段而言，更有可能是关于该词条的。字段长度归约的计算方法如下：

```
norm(d) = 1 / √numTerms
```

search 时, 使用 explain 可以拿到得分的计算详细信息

```
GET /my_index/doc/_search?explain
{
  "query": {
    "term": {
      "text": "fox"
    }
  }
}
```

### 向量空间模型

一个向量实际上就是一个包含了数值的一维数组，比如：

```
[1,2,5,22,3,8]
```

在向量空间模型中，向量中的每个数值都是由TF/IDF计算得到的一个词条的权重。

### Practical Scoring Function

```
   score(q,d)  = 
            queryNorm(q)  
          · coord(q,d)    
          · ∑ (           
                tf(t in d)   
              · idf(t)²      
              · t.getBoost() 
              · norm(t,d)    
            ) (t in q) 
```

**score(q,d)** 是文档d对于查询q的相关度分值。
**queryNorm(q)** 是查询归约因子(Query Normalization Factor)，是新添加的部分。
**coord(q,d)** 是Coordination Factor，是新添加的部分。
文档d中每个词条t对于查询q的权重之和。
**tf(t in d)** 是文档d中的词条t的词条频度(Term Frequency)。
**idf(t)** 是词条t的倒排索引频度(Inverse Document Frequency)
**t.getBoost()** 是适用于查询的提升(Boost)，是新添加的部分。
**norm(t,d)** 是字段长度归约(Field-length Norm)，可能结合了索引期间字段提
升(Index-time Field-level Boost)，是新添加的部分。

## Index and shards

数据存储到分片的过程是一定规则的，并不是随机发生的, 规则：shard = hash(routing) % number_of_primary_shards

Routing值可以是一个任意的字符串，默认情况下，它的值为存数数据对应文档 _id 值，
也可以是用户自定义的值。Routing这个字符串通过一个hash的函数处理，并返回一个数值，
然后再除以索引中主分片的数目，所得的余数作为主分片的编号，取值一般在0到number_of_primary_shards - 1的
这个范围中。通过这种方法计算出该数据是存储到哪个分片中。

正是这种路由机制，导致了主分片的个数为什么在索引建立之后不能修改。对已有索引主分片
数目的修改直接会导致路由规则出现严重问题，部分数据将无法被检索。

### 索引与删除一个文档

阶段1：客户端发送了一个索引或者删除的请求给node 1。

阶段2：node 1通过请求中文档的 _id 值判断出该文档应该被存储在shard 0 这个分片中，并且node 1知道shard 0的primary shard位于node 3这个节点上。因此node 1会把这个请求转发到node 3。

阶段3：node 3在shard 0 的primary shard上执行请求。如果请求执行成功，它node 3将并行地
将该请求发给shard 0的其余所有replica shard上，也就是存在于node 1和node 2中的replica shard。如果
所有的replica shard都成功地执行了请求，那么将会向node 3回复一个成功确认，当node 3收到了
所有replica shard的确认信息后，则最后向用户返回一个Success的消息。

### 更新一个文档

阶段1：客户端向node 1发送一个文档更新的请求。

阶段2：同样的node 1通过请求中文档的 _id 值判断出该文档应该被存储在shard 0 这个分片中，并
且node 1知道shard 0的primary shard位于node 3这个节点上。因此node 1会把这个请求转发到node 3。

阶段3：node 3从文档所在的primary shard中获取到它的JSON文件，并修改其中的_source中的内容，之后再重新
索引该文档到其primary shard中。

阶段4：如果node 3成功地更新了文档，node 3将会把文档新的版本并行地发给其余
所有的replica shard所在node中。这些node也同样重新索引新版本的文档，执行后则
向node 3确认成功，当node 3接收到所有的成功确认之后，再向客户端发送一个更新成功的信息。

### 检索文档
    
CRUD这些操作的过程中一般都是结合一些唯一的标记例如：_index，_type，以及routing的值，
这就意味在执行操作的时候都是确切的知道文档在集群中的哪个node中，哪个shard中。

而检索过程往往需要更多的执行模式，因为我们并不清楚所要检索的文档具体位置所在， 它们可能存在于ES集群中个
任何位置。因此，一般情况下，检索的执行不得不去询问index中的每一个shard。

但是，找到所有匹配检索的文档仅仅只是检索过程的一半，在向客户端返回一个结果列表之前，必
须将各个shard发回的小片的检索结果，拼接成一个大的已排好序的汇总结果列表。正因为这个原因，检索的过程将
分为查询阶段与获取阶段（Query Phase and Fetch Phase）。

**Query Phase**

在最初的查询过程中，查询请求会广播到index中的每一个primary shard和replica shard中，
每一个shard会在本地执行检索，并建立一个优先级队列（priority queue）。这个优先级队列是一
个根据文档匹配度这个指标所排序列表，列表的长度由分页参数from和size两个参数所决定。例如：

Query Phase阶段可以再细分成3个小的子阶段：

> 子阶段1：客户端发送一个检索的请求给node 3，此时node 3会创建一个空的优先级队列并且配置好分页参数from与size

> node 3将检索请求发送给该index中个每一个shard（这里的每一个意思是无论它是primary还是replica，它们
的组合可以构成一个完整的index数据）。每个shard在本地执行检索，并将结果添加到本地优先级队列中

> 每个shard返回本地优先级序列中所记录的_id与sort值，并发送node 3。Node 3将这些
值合并到自己的本地的优先级队列中，并做全局的排序

**Fetch Phase**

Query Phase主要定位了所要检索数据的具体位置，但是我们还必须取回它们才能完成整个检索过程。而Fetch Phase阶段的任务就是将这些定位好的数据内容取回并返回给客户端。

Fetch Phase过程可以分为三个子过程来描述：

> 子阶段1：node 3获取了所有待检索数据的定位之后，发送一个mget的请求给与数据相关的shard。
  
> 子阶段2：每个收到node 3的get请求的shard将读取相关文档_source中的内容，并将它们返回给node 3。
  
> 子阶段3：当node 3获取到了所有shard返回的文档后，node 3将它们合并成一条汇总的结果，返回给客户端。
  
## Segment

倒排索引表是 immutable 的, 它的好处在于

> There is no need for locking
> 可压缩

**处理变化**

Instead of rewriting the whole inverted index, add new supplementary indices 
to reflect more-recent changes. Each inverted index can be queried 
in turn—starting with the oldest—and the results combined.

Lucene, the Java libraries on which Elasticsearch is based, introduced the concept of 
per-segment search. A segment is an inverted index in its own right, but now the 
word index in Lucene came to mean a collection of segments plus a commit point—a 
file that lists all known segments

A per-segment search works as follows:

New documents are collected in an in-memory indexing buffer. 

Every so often, the buffer is commited:

> A new segment—a supplementary inverted index—is written to disk.

> A new commit point is written to disk, which includes the name of the new segment.

> The disk is fsync’ed—all writes waiting in the filesystem cache are flushed to disk, to ensure that they have been physically written.
> The new segment is opened, making the documents it contains visible to search.

>The in-memory buffer is cleared, and is ready to accept new documents.

### delete and update

When a document is “deleted,” it is actually just marked as deleted in the .del file. A
document that has been marked as deleted can still match a query, but it is removed from the 
results list before the final query results are returned.


Document updates work in a similar way: when a document is updated, the 
old version of the document is marked as deleted, and the new version of 
the document is indexed in a new segment. Perhaps both versions of the document 
will match a query, but the older deleted version is removed before the query 
results are returned.

### Near realtime search

The bottleneck is the disk. Commiting a new segment to disk requires an 
fsync to ensure that the segment is physically written to disk and that 
data will not be lost if there is a power failure. But an fsync is costly;
it cannot be performed every time a document is indexed without a big performance hit.

Sitting between Elasticsearch and the disk is the filesystem cache.

But the new segment is written to the filesystem cache first—which is cheap—and 
only later is it flushed to disk—which is expensive. But once a file is in the cache, 
it can be opened and read, just like any other file.

所以 in memory buffer 还不叫 segment

**refresh api**

In Elasticsearch, this lightweight process of writing and opening a new segment 
is called a refresh. By default, every shard is refreshed automatically once every second. 
This is why we say that Elasticsearch has near real-time search: document changes are not 
visible to search immediately, but will become visible within 1 second.

While a refresh is much lighter than a commit, it still has a performance cost. 
A manual refresh can be useful when writing tests, but don’t do a manual refresh every time 
you index a document in production; it will hurt your performance. Instead, your application needs 
to be aware of the near real-time nature of Elasticsearch and make allowances for it.

? commit 和 refresh 的关系


Segment


```java
public class Segment implements Streamable
    private String name;
    private long generation;
    public boolean committed;
    public boolean search;
    public long sizeInBytes = -1;
    public int docCount = -1;
    public int delDocCount = -1;
    public org.apache.lucene.util.Version version = null;
    public Boolean compound = null;
    public String mergeId;
    public long memoryInBytes;

```




索引段即lucene中的segments概念，我们知道ES索引过程
中会refresh和tranlog也就是说我们在索引过程中segments number不只一
个。而segments number与检索是有直接联系的，segments number越多检索越慢，而将segments numbers 有可能
的情况下保证为1，这将可以提高将近一半的检索速度。


## Geolocation & geohashes

## 一致性

Discovery.zen
代表ES的自动发现节点机制，ES是一个基于p2p的系统，它先通过广播寻找存在的节点，再通过多播协议来进行节点之间的通信，同时也支持点对点的交互。


## 桶与指标

[link](http://blog.csdn.net/dm_vincent/article/details/42387161)

**Buckets(桶)：**

满足某个条件的文档集合。

>   一名员工要么属于男性桶，或者女性桶。

>   城市Albany属于New York州这个桶。

>   日期2014-10-28属于十月份这个桶。

ES中有很多类型的桶，让你可以将文档通过多种方式进行划分(按小时，按最流行的词条，
按年龄区间，按地理位置，以及更多)。但是从根本上，它们都根据相同的原理运作：按照条件对文档进行划分。


**Metrics(指标)：**

为某个桶中的文档计算得到的统计信息。


桶能够让我们对文档进行有意义的划分，但是最终我们还是需要对每个桶中的文档进行某种指标计算。分桶是达到最终目的的手段：提供了对文档进行划分的方法，从而让你能够计算需要的指标。

多数指标仅仅是简单的数学运算(比如，min，mean，max以及sum)，它们使用文档中的值进行计算。在实际应用中，指标能够让你计算例如平均薪资，最高出售价格，或者百分之95的查询延迟。

就是这样！每个聚合只是简单地由一个或者多个桶，零个或者多个指标组合而成。可以将它粗略地转换为SQL：

SELECT COUNT(color) 
FROM table
GROUP BY color
以上的COUNT(color)就相当于一个指标。GROUP BY color则相当于一个桶。

桶和SQL中的组(Grouping)拥有相似的概念，而指标则与COUNT()，SUM()，MAX()等相似。

### combined

一个聚合就是一些桶和指标的组合。一个聚合可以只有一个桶，或者一个指标，或者每样一个。在桶中甚至可以有多个嵌套的桶。比如，我们可以将文档按照其所属国家进行分桶，然后对每个桶计算其平均薪资(一个指标)。

因为桶是可以嵌套的，我们能够实现一个更加复杂的聚合操作：

> 将文档按照国家进行分桶。(桶)

> 然后将每个国家的桶再按照性别分桶。(桶)

> 然后将每个性别的桶按照年龄区间进行分桶。(桶)

> 最后，为每个年龄区间计算平均薪资。(指标)
